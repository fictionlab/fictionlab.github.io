---
title: Hokuyo URG-04LX-UG01
sidebar_label: Hokuyo URG-04LX-UG01
keywords:
  - hokuyo
  - lidar
  - 2d
  - leo
  - integration
  - example
description: >
  Learn how to connect a Hokuyo LiDAR sensor to your Leo Rover for mapping,
  object detection, and SLAM applications.
image: /img/robots/leo/integrations/hokuyo-lidar/hokuyo-lidar.webp
---

import Product from '@site/docs/leo-rover/addons/powerbox/_powerbox-product.mdx';
import LiteYouTubeEmbed from 'react-lite-youtube-embed';

This tutorial will guide you through the process of connecting a LiDAR sensor to
your Leo Rover.

Light Detection and Ranging devices, or lidars for short, are mechanisms used
for mapping the environment, object detection, tracking the speed of vehicles
and in a vide range of other applications. In robotics 2D lidars, like RPLidar
A2M8, are used for things such as indoor SLAM
([Simultaneous localization and mapping](https://en.wikipedia.org/wiki/Simultaneous_localization_and_mapping))
or safety systems.

<ImageZoom
  loading="eager"
  src="/img/robots/leo/integrations/hokuyo-lidar/hokuyo-lidar.webp"
  width="1350"
  height="1350"
  figStyle={{
    width: 400,
  }}
/>

The steps might slightly differ for other LiDAR sensors but should be
essentially similar.

## What to expect?

After completing this tutorial, you should be able to visualize the model and
data from the sensor like in the video below.

<div className="video-container">
  <LiteYouTubeEmbed
    id="oD5Sp7T0Ki0"
    params="autoplay=0&autohide=1&showinfo=0&rel=0"
    poster="hqdefault"
    title="Leo Rover Unboxing and Getting Started"
    webp
  />
</div>

## Prerequisites

<LinkButton docId="leo-rover/guides/ssh" />
<LinkButton docId="leo-rover/advanced-guides/ros-development" />

## List of components

- Hokuyo URG-04LX-UG01
- 3D-printed 04008 Hokuyo URG-04LX adapter
  ([available here](/docs/leo-rover/integrations/addon-adapters#hokuyo-urg-04lx-adapter))
- miniUSB-USB A cable (provided by default with Leo Rover)
- 4x M5x10 mounting screws
- 2x M3x10 mounting screws

## Mechanical integration

:::info

When mounting the sensor, you should be particularly careful not to obstruct the
field of view by other parts of the Rover.

:::

We developed 3D printable models of mechanical interfaces that allow you to
mount the aforementioned sensor to the mounting plate of the rover. Locating the
sensor the top of the robot provides a vide field of view with not many
obstacles for the laser beam to get caught on. Get the files from here:
[Addon Adapters](/docs/leo-rover/integrations/addon-adapters).

- With 2x M3x6 Allen screws connect the sensor to the printed interface plate.
- Use 4x M5x10 Allen screws to fasten the sensor to the Leo Rover.

## Wiring and electronics connection

The sensor can be connected to the robot's main computer via the USB socket
positioned at the top of the rover.

USB connection provides power to the sensor and allows the data transfer. This
means that no external power sources are necessary. Some lidars might need
external power connections, that's when
[Powerbox](/docs/leo-rover/addons/powerbox) might come in handy.

<Product />

With everything connected Leo Rover looks like this:

<ImageZoom
  src="/img/robots/leo/integrations/hokuyo-lidar/leo-with-hokuyo-lidar.webp"
  width="1500"
  height="1125"
/>

## Software integration

The first thing you can do is to make sure your device has the correct
permissions and is available at the fixed path on your system. To do this, you
can add the following rule to the udev service:

```xml title="/etc/udev/rules.d/lidar.rules"
KERNEL=="ttyACM*", ATTRS{idVendor}=="15d1", MODE="0666", GROUP="dialout", SYMLINK+="lidar", ENV{ID_MM_DEVICE_IGNORE}="1"
```

Paste these lines to `/etc/udev/rules.d/lidar.rules` file and reload udev rules
by typing:

```bash
sudo udevadm control --reload-rules && sudo udevadm trigger
```

Your device should now be available at the `/dev/lidar` path.

We want the sensor functionality to be available in the ROS ecosystem, so you
should install a ROS package that provides a node for the sensor you are trying
to integrate.

```bash
sudo apt install ros-${ROS_DISTRO}-urg-node
```

Now, create a launch file that would start the node with a fitting
configuration.

```xml title="/etc/ros/laser.launch"
<launch>
  <node name="urg_node" pkg="urg_node" type="urg_node" output="log">
    <param name="port" value="/dev/lidar"/>
    <param name="frame_id" value="laser_frame"/>
    <param name="calibrate_time" value="true"/>
  </node>
</launch>
```

Include your launch file in the `robot.launch` file, so that your node will
start at boot.

```xml title="/etc/ros/robot.launch"
<include file="/etc/ros/laser.launch"/>
```

Your robot should be aware of where the scanner is located and what space it
occupies. You can ensure it does that by creating a URDF model of the sensor.

```xml title="/etc/ros/urdf/laser.urdf.xacro"
<?xml version="1.0"?>
<robot>

  <link name="hokuyo_link">
    <visual>
      <origin xyz="0 0 0.003"/>
      <geometry>
        <box size="0.079 0.05 0.006"/>
      </geometry>
      <material name="support">
        <color rgba="0.5 0.5 0.5 1.0"/>
      </material>
    </visual>
    <visual>
      <origin xyz="0 0 0.041"/>
      <geometry>
        <box size="0.05 0.05 0.07"/>
      </geometry>
      <material name="lidar">
        <color rgba="1.0 0.0 0.0 0.7"/>
      </material>
    </visual>
    <collision>
      <origin xyz="0 0 0.003"/>
      <geometry>
        <box size="0.079 0.05 0.006"/>
      </geometry>
    </collision>
    <collision>
      <origin xyz="0 0 0.041"/>
      <geometry>
        <box size="0.05 0.05 0.07"/>
      </geometry>
    </collision>
  </link>

  <joint name="hokuyo_joint" type="fixed">
    <origin xyz="0.0775 0 0"/>
    <parent link="base_link"/>
    <child link="hokuyo_link"/>
  </joint>

  <link name="laser_frame"/>

  <joint name="laser_joint" type="fixed">
    <origin xyz="0 0 0.064"/>
    <parent link="hokuyo_link"/>
    <child link="laser_frame"/>
  </joint>

</robot>
```

And including it in the description that is uploaded at boot.

```xml title="/etc/ros/urdf/robot.urdf.xacro"
<xacro:include filename="/etc/ros/urdf/laser.urdf.xacro"/>
```

:::tip

You can experiment with the URDF file and create a more representative model of
the sensor by adding more visual and collision tags or by including meshes in
STL or COLLADA format.

:::

The last step is to either reboot the robot or restart the leo service.

```bash
sudo systemctl restart leo
```

## Examples

### Reading and visualizing the data of the Hokuyo laser scanner

The robot should now publish the
[LaserScan messages](http://docs.ros.org/api/sensor_msgs/html/msg/LaserScan.html)
on the `/scan` topic. You can check the raw data that it sends by typing:

```bash
rostopic echo /scan
```

If you have ROS installed on your computer, you can get a more graphical
representation of the data with RViz. If you don't have ROS, you can follow this
guide:

<LinkButton docId="leo-rover/advanced-guides/install-ros-on-your-computer" />

Before starting RViz, make sure you completed the **Connecting another computer
to ROS network** section of **ROS Development** tutorial:

<LinkButton docId="leo-rover/advanced-guides/ros-development" />

Now, open RViz by typing `rviz` in the terminal, or, if you have the `leo_viz`
package installed, type:

```bash
roslaunch leo_viz rviz.launch
```

This will start RViz with visualization of the current robot model.

On the Displays panel click **Add** -> **By topic** and search for the `/scan`
topic. Choose the **LaserScan** display and click **Ok**.

<ImageZoom
  src="/img/robots/leo/integrations/hokuyo-lidar/rviz-laser-scan.webp"
  width="1362"
  height="727"
/>

You should now be able to see the data from the sensor visualized as points in
3D space.

To put the points into the camera image, you can also add the **Camera**
display.

<ImageZoom
  src="/img/robots/leo/integrations/hokuyo-lidar/rviz-add-camera.webp"
  width="1364"
  height="730"
/>

Be sure to check `compressed` as the Transport Hint and `/camera/image_raw` as
the Image Topic.

<ImageZoom
  src="/img/robots/leo/integrations/hokuyo-lidar/rviz-camera-topic.webp"
  width="1365"
  height="729"
/>

## What next?

Lidars are commonly used in projects involving
[autonomous navigation](/docs/leo-rover/advanced-guides/autonomous-navigation),
you might be interested in a tutorial about it.

They are however, not the only way of teaching a Leo Rover how to move on it's
own. Check out our [line follower](/docs/leo-rover/leo-examples/line-follower)
tutorial if you want to learn more. You can also check our
[Integrations page](/docs/category/integrations) for more instructions.
